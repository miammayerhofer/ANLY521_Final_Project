{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on ACLU Bill Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN THE DATA\n",
    "data = pd.read_csv(\"../modified_data/merged_bill_data.csv\")\n",
    "# Drop the unnamed column\n",
    "data = data.drop(data.columns[0], axis = 1)\n",
    "# Get the number of characters in each bill\n",
    "data[\"number_characters\"] = data[\"text\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Option 1: Tokenizing with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"nltk_tokens\"] = [word_tokenize(text) for text in data[\"text\"]]\n",
    "# Get the number of tokens with NLTK in each bill\n",
    "data[\"number_nltk_tokens\"] = data[\"nltk_tokens\"].str.len()\n",
    "# Get the number of bills with less than or equal to 512 tokens\n",
    "len(data[(data[\"number_nltk_tokens\"] < 512)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Option 2: Removing Whitespace + Word Ninja Inference Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/d81k_b_93575z7h2220jh4cr0000gn/T/ipykernel_6376/1212223077.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data[\"text_no_spaces\"] = data[\"text\"].str.replace(r'\\s+', '')\n",
      "/var/folders/_p/d81k_b_93575z7h2220jh4cr0000gn/T/ipykernel_6376/1212223077.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.infered_wordninja_words[i] = wordninja.split(data.text_no_spaces[i])\n"
     ]
    }
   ],
   "source": [
    "# Make a column of the text without spaces\n",
    "data[\"text_no_spaces\"] = data[\"text\"].str.replace(r'\\s+', '')\n",
    "# Make a new column of infered words\n",
    "data[\"infered_wordninja_words\"] = \"\"\n",
    "# Infer the words from this new column\n",
    "for i in range(len(data.text_no_spaces)):\n",
    "    data.infered_wordninja_words[i] = wordninja.split(data.text_no_spaces[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of tokens with wordninja method\n",
    "data[\"number_wordninja_tokens\"] = data[\"infered_wordninja_words\"].str.len()\n",
    "# Get the number of bills with less than or equal to 512 tokens\n",
    "len(data[(data[\"number_wordninja_tokens\"] < 512)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('anly521')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77566a2c3ddae237484c9e2ee11aa0d0d130c667ddac0346d8d50ca9701792c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
